{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66d3bdff-76d5-4020-8f18-8032e79372cd",
   "metadata": {},
   "source": [
    "## IIIc- Conversion to numpy\n",
    "\n",
    "In order to train our future model on the features of the images, I want to convert the images into Numpy array. \n",
    "\n",
    "Indeed, this would allow for operations to be based on numerical arrays, which would in turn increase the speed of my model.\n",
    "\n",
    "To do so, I:\n",
    "- check the number of images per label, \n",
    "- create numpy arrays for both images and labels,\n",
    "- create training and test datasets,\n",
    "- save all the tables under a numpy format.\n",
    "\n",
    "Here I show the process on the images I equalized and for which I've limited the number to 100 images. \n",
    "\n",
    "This same process was applied to the other files containing the non-equalized pictures, with and without limitation in the number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9d7ac67f-621e-4e13-afdd-2913c9819862",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hypertension = 99\n",
      "Cataract = 99\n",
      "Glaucoma = 99\n",
      "Others = 99\n",
      "AMD = 99\n",
      "Diabetes = 99\n",
      "Normal = 99\n",
      "Myopia = 99\n"
     ]
    }
   ],
   "source": [
    "# Imports:\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "#Path:\n",
    "PATH_DST = '/Users/user/Desktop/Datascientest/Fil_rouge/Images_file/4c-ODIR-5K_Training_Equal_limited/'\n",
    "FILE_NAME_FEATURES = 'X_Eq_lim'                            \n",
    "FILE_NAME_TARGET = 'y_Eq_lim' \n",
    "\n",
    "# Show image count for each file in PATH_DST\n",
    "list_classe = os.listdir(PATH_DST)\n",
    "list_all_images = []\n",
    "train = []\n",
    "labels = []\n",
    "for classe in list_classe:\n",
    "    path = os.path.join(PATH_DST, classe)\n",
    "    list_images = [f for f in os.listdir(path) if os.path.isfile(os.path.join(path, f))]\n",
    "    print(f'{classe} = {len(list_images)}')\n",
    "    for image_name in list_images:\n",
    "        image = cv2.imread(os.path.join(path, image_name))\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        train.append(image)\n",
    "        labels.append(classe)\n",
    "        list_all_images.append(image_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f98ec050-03d3-478c-928d-999d4aada01b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create array for both images and labels \n",
    "# and reshape the images-related arrays to fit the model\n",
    "training_aug = np.array(train, dtype='uint8')\n",
    "training_aug = np.reshape(training_aug, [training_aug.shape[0], training_aug.shape[1], training_aug.shape[2], training_aug.shape[3]])\n",
    "labels_aug = np.array(labels)\n",
    "ID = np.array(list_all_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f76c8264-6d4a-446f-916b-16c8bfe15ac0",
   "metadata": {},
   "source": [
    "I now create training and testing testing sets ofr later use in our model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7b548ece-3d3f-495e-8e1c-593d1b330c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(training_aug, labels_aug, test_size = 0.2, random_state = 123, stratify = labels_aug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f1fd3528-8d9a-45fa-bfa4-37e7de056c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_1, X_train_2, y_train_1, y_train_2 = train_test_split(X_train, y_train, test_size = 0.4, random_state = 123)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1a5be4f-86f9-4eaf-8bec-30a9a318018f",
   "metadata": {},
   "source": [
    "I now save all numpy arrays:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "aa0837cf-4c33-4aa3-9bc4-b682c9086ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(FILE_NAME_FEATURES+'_train_1', X_train_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ec46dae4-b7d1-4373-a02e-e826209795bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(FILE_NAME_FEATURES+'_train_2', X_train_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d522cbfd-472b-4850-b0b0-06b6b625b4e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(FILE_NAME_FEATURES+'_test', X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8ce4bbbb-1f5e-402c-9313-cb0f5977fde0",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(FILE_NAME_TARGET+'_train_1', y_train_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "54ebf3d7-65a8-4a4b-84b6-cad5cb2873d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(FILE_NAME_TARGET+'_train_2', y_train_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "31e0ddd2-4a11-46d1-a71d-2d8f71fdc43a",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(FILE_NAME_TARGET+'_test', y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5ec491b0-b9cf-46d7-8fd7-c4077ac7226a",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('Eq_lim', ID)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
